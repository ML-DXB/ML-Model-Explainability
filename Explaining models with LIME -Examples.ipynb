{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining a Tabular Model with LIME\n",
    "\n",
    "\n",
    "Algorithms applied:\n",
    "- Titanic: classifiers from LGBM, CatBoost, XGBoost\n",
    "- Heart disease UCI: Keras multi-layer perceptron NN architecture\n",
    "- Boston housing dataset: regressor from XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n",
      "/kaggle/input/heart-disease-uci/heart.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#gender_submission.csv is an example prediction file predicting all female passengers survive, and no others do\n",
    "#!cat /kaggle/input/titanic/gender_submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining Titanic Survival Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  train  \n",
       "0      0         A/5 21171   7.2500   NaN        S      1  \n",
       "1      0          PC 17599  71.2833   C85        C      1  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S      1  \n",
       "3      0            113803  53.1000  C123        S      1  \n",
       "4      0            373450   8.0500   NaN        S      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"train\"] = 1\n",
    "df_test[\"train\"] = 0\n",
    "df_all = pd.concat([df_train, df_test], sort=False)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embarked column has some null values. Filling those with some value that is not in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[\"Embarked\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"Embarked\"] = df_all[\"Embarked\"].fillna(\"N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are some extra features I picked up earlier from various Titanic kernels here at Kaggle. Unfortunately that was a while back and I lost all the references to the original ones, but thanks anyway:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cabin_type(x):\n",
    "    if pd.isnull(x):\n",
    "        return None\n",
    "    #print(\"X:\"+x[0])\n",
    "    #cabin id consists of letter+numbers. letter is the type/deck, numbers are cabin number on deck\n",
    "    return x[0]\n",
    "\n",
    "def parse_cabin_number(x):\n",
    "    if pd.isnull(x):\n",
    "        return -1\n",
    "#        return np.nan\n",
    "    cabs = x.split()\n",
    "    cab = cabs[0]\n",
    "    num = cab[1:]\n",
    "    if len(num) < 2:\n",
    "        return -1\n",
    "        #return np.nan\n",
    "    return num\n",
    "\n",
    "def parse_cabin_count(x):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan\n",
    "    #a typical passenger has a single cabin but some had multiple. in that case they are space separated\n",
    "    cabs = x.split()\n",
    "    return len(cabs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>train</th>\n",
       "      <th>cabin_type</th>\n",
       "      <th>cabin_num</th>\n",
       "      <th>cabin_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>85</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>123</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  train cabin_type  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S      1       None   \n",
       "1      0          PC 17599  71.2833   C85        C      1          C   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S      1       None   \n",
       "3      0            113803  53.1000  C123        S      1          C   \n",
       "4      0            373450   8.0500   NaN        S      1       None   \n",
       "\n",
       "   cabin_num  cabin_count  \n",
       "0         -1          NaN  \n",
       "1         85          1.0  \n",
       "2         -1          NaN  \n",
       "3        123          1.0  \n",
       "4         -1          NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[\"cabin_type\"] = df_all[\"Cabin\"].apply(lambda x: parse_cabin_type(x))\n",
    "df_all[\"cabin_num\"] = df_all[\"Cabin\"].apply(lambda x: parse_cabin_number(x))\n",
    "df_all[\"cabin_count\"] = df_all[\"Cabin\"].apply(lambda x: parse_cabin_count(x))\n",
    "df_all[\"cabin_num\"] = df_all[\"cabin_num\"].astype(int)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>train</th>\n",
       "      <th>cabin_type</th>\n",
       "      <th>cabin_num</th>\n",
       "      <th>cabin_count</th>\n",
       "      <th>family_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  train cabin_type  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S      1       None   \n",
       "1      0          PC 17599  71.2833   C85        C      1          C   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S      1       None   \n",
       "3      0            113803  53.1000  C123        S      1          C   \n",
       "4      0            373450   8.0500   NaN        S      1       None   \n",
       "\n",
       "   cabin_num  cabin_count  family_size  \n",
       "0         -1          NaN            2  \n",
       "1         85          1.0            2  \n",
       "2         -1          NaN            1  \n",
       "3        123          1.0            2  \n",
       "4         -1          NaN            1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[\"family_size\"] = df_all[\"SibSp\"] + df_all[\"Parch\"] + 1\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>train</th>\n",
       "      <th>cabin_type</th>\n",
       "      <th>cabin_num</th>\n",
       "      <th>cabin_count</th>\n",
       "      <th>family_size</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  train cabin_type  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S      1       None   \n",
       "1      0          PC 17599  71.2833   C85        C      1          C   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S      1       None   \n",
       "3      0            113803  53.1000  C123        S      1          C   \n",
       "4      0            373450   8.0500   NaN        S      1       None   \n",
       "\n",
       "   cabin_num  cabin_count  family_size Title  \n",
       "0         -1          NaN            2    Mr  \n",
       "1         85          1.0            2   Mrs  \n",
       "2         -1          NaN            1  Miss  \n",
       "3        123          1.0            2   Mrs  \n",
       "4         -1          NaN            1    Mr  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning name and extracting Title\n",
    "for name_string in df_all['Name']:\n",
    "    df_all['Title'] = df_all['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing rare titles \n",
    "mapping = {'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs', 'Major': 'Other', \n",
    "           'Col': 'Other', 'Dr' : 'Other', 'Rev' : 'Other', 'Capt': 'Other', \n",
    "           'Jonkheer': 'Royal', 'Sir': 'Royal', 'Lady': 'Royal', \n",
    "           'Don': 'Royal', 'Countess': 'Royal', 'Dona': 'Royal'}\n",
    "           \n",
    "df_all.replace({'Title': mapping}, inplace=True)\n",
    "#titles = ['Miss', 'Mr', 'Mrs', 'Royal', 'Other', 'Master']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df_all[\"Title\"].unique()\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = list(titles)\n",
    "# Replacing missing age by median age for title \n",
    "for title in titles:\n",
    "    age_to_impute = df_all.groupby('Title')['Age'].median()[titles.index(title)]\n",
    "    df_all.loc[(df_all['Age'].isnull()) & (df_all['Title'] == title), 'Age'] = age_to_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all[\"Fare\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[152]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3_median_fare = df_all[df_all[\"Pclass\"] == 3][\"Fare\"].median()\n",
    "p3_median_fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"Fare\"].fillna(p3_median_fare, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[152]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop([\"Name\", \"Ticket\", \"Cabin\", \"PassengerId\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"cabin_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"cabin_type\"] = df_all[\"cabin_type\"].fillna(\"Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"cabin_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode_cols = [\"Sex\", \"Embarked\", \"Title\", \"cabin_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in label_encode_cols:\n",
    "    le = LabelEncoder()\n",
    "    label_encoders[col] = le\n",
    "    df_all[col] = le.fit_transform(df_all[col])\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = label_encode_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    df_all[col] = df_all[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"cabin_count\"] = df_all[\"cabin_count\"].fillna(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encode for XGBoost\n",
    "\n",
    "LGBM and CatBoost can use categorical columns as is, but XGBoost needs one-hot encoding. So the \"_oh\" ending dataframes created here are the same as the ones without the ending, but one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_oh = pd.get_dummies( df_all, columns = cat_cols )\n",
    "df_all_oh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_oh.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_all[df_all[\"train\"] == 1]\n",
    "df_test = df_all[df_all[\"train\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_oh = df_all_oh[df_all_oh[\"train\"] == 1]\n",
    "df_test_oh = df_all_oh[df_all_oh[\"train\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(\"train\", axis=1)\n",
    "df_test = df_test.drop(\"train\", axis=1)\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_oh = df_train_oh.drop(\"train\", axis=1)\n",
    "df_test_oh = df_test_oh.drop(\"train\", axis=1)\n",
    "df_train_oh.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_train[\"Survived\"]\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(\"Survived\", axis=1)\n",
    "df_test = df_test.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_oh = df_train_oh.drop(\"Survived\", axis=1)\n",
    "df_test_oh = df_test_oh.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_oh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Booster Classifiers\n",
    "\n",
    "Here I create the boosting classifiers. The hyperparameters are not especially tuned since the point of this notebook is to explore LIME for feature explanations, not to optimize for fractions of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "l_clf = lgb.LGBMClassifier(\n",
    "                        num_leaves=1024,\n",
    "                        learning_rate=0.01,\n",
    "                        n_estimators=5000,\n",
    "                        boosting_type=\"gbdt\",\n",
    "                        min_child_samples = 100,\n",
    "                        verbosity = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clf = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "\n",
    "c_clf = catboost.CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_train\n",
    "y = target\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_oh = df_train_oh\n",
    "X_train_oh, X_val_oh = train_test_split(X_oh, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_oh.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit all boosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the if True parts are just to make it simpler to disable some algorithm.\n",
    "\n",
    "if True:\n",
    "    l_clf.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='mae',\n",
    "        early_stopping_rounds=5,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "if True:\n",
    "    c_clf.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        early_stopping_rounds=5,\n",
    "        cat_features=cat_cols,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "if True:\n",
    "    x_clf.fit(\n",
    "        X_train_oh, y_train,\n",
    "        eval_set=[(X_val_oh, y_val)],\n",
    "        early_stopping_rounds=5,\n",
    "        verbose=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance from Classifier\n",
    "\n",
    "Plot the overall feature importance given by the algorithms themselves:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feat_importance(clf, train):\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        importances = clf.feature_importances_\n",
    "        features = train.columns\n",
    "\n",
    "        feat_importances = pd.DataFrame()\n",
    "        feat_importances[\"weight\"] = importances\n",
    "        feat_importances.index = features\n",
    "        feat_importances.sort_values(by=\"weight\", ascending=False).to_csv(f\"top_features.csv\")\n",
    "        feat_importances.nlargest(30, [\"weight\"]).sort_values(by=\"weight\").plot(kind='barh', title=f\"top features\", color='#86bf91', figsize=(10, 8))\n",
    "        # kaggle shows output image files (like this png) under \"output visualizations\", others (such as pdf) under \"output\"\n",
    "        plt.savefig(f'feature-weights.png')\n",
    "        plt.savefig(f'feature-weights.pdf')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot permutation importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_pimp(pimps, train):\n",
    "    importances = pimps.importances_mean\n",
    "    features = train.columns\n",
    "\n",
    "    feat_importances = pd.DataFrame()\n",
    "    feat_importances[\"weight\"] = importances\n",
    "    feat_importances.index = features\n",
    "    feat_importances.sort_values(by=\"weight\", ascending=False).to_csv(f\"top_features.csv\")\n",
    "    feat_importances.nlargest(30, [\"weight\"]).sort_values(by=\"weight\").plot(kind='barh', title=f\"top features\", color='#86bf91', figsize=(10, 8))\n",
    "    # kaggle shows output image files (like this png) under \"output visualizations\", others (such as pdf) under \"output\"\n",
    "    plt.savefig(f'feature-weights.png')\n",
    "    plt.savefig(f'feature-weights.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feat_importance(l_clf, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "l_pimps = permutation_importance(l_clf, X_train, y_train, n_repeats=10, random_state=0)\n",
    "dir(l_pimps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pimp(l_pimps, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feat_importance(c_clf, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_pimps = permutation_importance(c_clf, X_train, y_train, n_repeats=10, random_state=0)\n",
    "plot_pimp(c_pimps, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_pimps.importances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[np.argmin(c_pimps.importances_mean)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, permutation importance actually ranks \"Parch\" as contributing negatively to prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feat_importance(x_clf, X_train_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pimps = permutation_importance(x_clf, X_train_oh, y_train, n_repeats=10, random_state=0)\n",
    "plot_pimp(x_pimps, X_train_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three seem to rank very similar features highest overall. Title, gender, passenger class, fare, ... I expect fare to be a kind of a proxy for passenger class, which likely defines something about your location on the ship, and so on.\n",
    "\n",
    "XGBoost here has much more variables that LGBM or CatBoost. Since XGBoost uses one-hot encoded variables, it has a much larger number of \"features\", which are just different values of a categorical variable. However, it also shows to rank a specific gender and title higher, so overall its is very similar.\n",
    "\n",
    "The less weighted variables seem to have much more variation across the classifiers, but as far as I could tell including them still provides some small gains in accuracy. Just that the specific ways they are combined by the different classifiers has some variation, although results are very similar.\n",
    "\n",
    "The difference between the lower ranked features is something that also comes up later with my LIME experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "val_pred_proba = l_clf.predict_proba(X_val)\n",
    "#val_pred = np.array(val_pred[:, 1] > 0.5)\n",
    "val_pred = np.where(val_pred_proba > 0.5, 1, 0)\n",
    "\n",
    "acc_score = accuracy_score(y_val, val_pred[:,1])\n",
    "acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_proba = c_clf.predict_proba(X_val)\n",
    "#val_pred = np.array(val_pred[:, 1] > 0.5)\n",
    "val_pred = np.where(val_pred_proba > 0.5, 1, 0)\n",
    "\n",
    "acc_score = accuracy_score(y_val, val_pred[:,1])\n",
    "acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_proba = x_clf.predict_proba(X_val_oh)\n",
    "#val_pred = np.array(val_pred[:, 1] > 0.5)\n",
    "val_pred = np.where(val_pred_proba > 0.5, 1, 0)\n",
    "\n",
    "acc_score = accuracy_score(y_val, val_pred[:,1])\n",
    "acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up LIME parameters\n",
    "\n",
    "Running the LIME explainer requires \n",
    "- a list of features\n",
    "- a prediction function\n",
    "- a function to translate data from LIME format to prediction algorithm format\n",
    "- list of categorical variable names\n",
    "- list of categorical variable indices\n",
    "- list of value names for categorical variables\n",
    "\n",
    "The categorical variable data are used to define how LIME will permutate variables (categorical vs continous), and how it will display the results (variables and values have names vs numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(df_train.columns)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_cols was set up earliner in the notebook to contain list of categorical feature/column names\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the corresponding indices of the cat_cols columns in the list of features\n",
    "cat_indices = [feature_names.index(col) for col in cat_cols]\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping the category values to their names. for example, {\"sex\"={0=\"female\", 1=\"male\"}}\n",
    "cat_names = {}\n",
    "for label_idx in cat_indices:\n",
    "    label = feature_names[label_idx]\n",
    "    print(label)\n",
    "    le = label_encoders[label]\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    le_value_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "    print(le_value_mapping)\n",
    "    cat_names[label_idx] = le_value_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names #its actually the feature index mapped to the values and their names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(df_train.values, discretize_continuous=True,\n",
    "                                                   class_names=['not survived', 'survived'], \n",
    "                                                   mode=\"classification\",\n",
    "                                                   feature_names = feature_names,\n",
    "                                                   categorical_features=cat_indices,\n",
    "                                                   categorical_names=cat_names, \n",
    "                                                   kernel_width=10, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to run Classifiers from LIME\n",
    "\n",
    "LIME takes a datapoint, generates N (by default N=5000) synthetic samples around it, and runs the classifier on those synthetic samples to get some estimate on the effects of features. In many classifiers, LIME uses different format for the dataframes than the actual classifier you give it, so have to write a function to convert them to classifier format. The following are functions to do that for LGBM, CatBoost, XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def row_to_df(row):\n",
    "#    rows = []\n",
    "#    rows.append(X_val.values[0])\n",
    "#    df = pd.DataFrame(rows, columns=X_val.columns)\n",
    "#    for col in cat_cols:\n",
    "#        df[col] = df[col].astype('category')    \n",
    "#    return df\n",
    "\n",
    "#when LIME passes synthetic data to your predict function, it gives a list of N synthetic datapoints as a numpy matrix\n",
    "#this converts that matrix into a dataframe, since some algorithms choke on the pure numpy array (catboost)\n",
    "def rows_to_df(rows):\n",
    "    df = pd.DataFrame(rows, columns=X_val.columns)\n",
    "    #set category columns first to short numeric to save memory etc, then convert to categorical for catboost\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].astype('int8')\n",
    "        df[col] = df[col].astype('category')\n",
    "    #and finally convert all non-categoricals to their original type. since we had to create a fresh dataframe this is needed\n",
    "    for col in X_val.columns:\n",
    "        if col not in cat_cols:\n",
    "            df[col] = df[col].astype(X_val[col].dtype)\n",
    "    return df\n",
    "\n",
    "#for one-hot encoding the values from LIME, which uses numbers in a single column to represent categories\n",
    "#needed for xgboost\n",
    "def rows_to_df_oh(rows):\n",
    "    df = pd.DataFrame(rows, columns=X_val_oh.columns)\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].astype('int8')\n",
    "    return df\n",
    "\n",
    "#the function to pass to LIME for running catboost on the synthetic data\n",
    "def c_run_pred(x):\n",
    "    p = c_clf.predict_proba(rows_to_df(x))\n",
    "    return p\n",
    "\n",
    "#the function to pass to LIME to run LGBM on the synthetic data\n",
    "def l_run_pred(x):\n",
    "    p = l_clf.predict_proba(x)\n",
    "    return p\n",
    "\n",
    "#the function to pass to LIME to run XGBoost on the synthetic data\n",
    "def x_run_pred(x):\n",
    "    df = rows_to_df(x)\n",
    "    df = pd.get_dummies( df, columns = cat_cols )\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "    #this look ensure the column order of the dataframe created is same as the original\n",
    "    for col in X_val_oh.columns:\n",
    "        if col in df.columns:\n",
    "            new_df[col] = df[col]\n",
    "        else:\n",
    "            #sometimes it seems to happen that a specific value is missing from a category in generation,\n",
    "            #which leads to missing that column. this zeroes it to ensure it exists\n",
    "            #print(f\"missed col:{col}\")\n",
    "            new_df[col] = 0\n",
    "    df = new_df\n",
    "\n",
    "    p = x_clf.predict_proba(df)\n",
    "    return p\n",
    "\n",
    "c_predict_fn = lambda x: c_run_pred(x)\n",
    "\n",
    "l_predict_fn = lambda x: l_run_pred(x)\n",
    "\n",
    "x_predict_fn = lambda x: x_run_pred(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_clf.predict_proba([X_val.values[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_predict_fn(X_val.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict_fn(X_val.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_clf.predict_proba(X_val_oh)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this demonstrates the missing value branch of x_run_pred() with cabin_type=7\n",
    "df = rows_to_df(X_val.values)\n",
    "print(df.shape)\n",
    "print(f\"cat cols: {cat_cols}\")\n",
    "df = pd.get_dummies( df, columns = cat_cols )\n",
    "missing_cols = set( X_val_oh.columns ) - set( df.columns )\n",
    "print(f\"missing: {missing_cols}\")\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "new_df = pd.DataFrame()\n",
    "for col in X_val_oh.columns:\n",
    "    if col in df.columns:\n",
    "        new_df[col] = df[col]\n",
    "    else:\n",
    "        new_df[col] = 0\n",
    "df = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = x_clf.predict_proba(df)\n",
    "#p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_predict_fn(X_val.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining a Datapoint with LIME / Booster Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_item(predictor, item):\n",
    "    exp = explainer.explain_instance(item, predictor, num_features=10, top_labels=1)\n",
    "    exp.show_in_notebook(show_table=True, show_all=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 1 explained\n",
    "\n",
    "I will run the explainer first once per datapoint. Starting with point 1, or index 0 in the dataset. And then modify one of the higher ranked features to see if it has some effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this allows running the experiments N times to see if the random synthetic value generation of LIME has some effect on the results over different runs.\n",
    "\n",
    "def explain_x_times(x, idx, invert_gender=False):\n",
    "    row = X_val.values[idx]\n",
    "    if invert_gender:\n",
    "        if row[1] > 0:\n",
    "            row[1] = 0\n",
    "        else:\n",
    "            row[1] = 1\n",
    "    print(f\"columns={X_val.columns}\")\n",
    "    \n",
    "    for i in range(x):\n",
    "        print(f\"Explaining LGBM: index={idx}, row={row}\")\n",
    "        explain_item(l_predict_fn, row)\n",
    "    for i in range(x):\n",
    "        print(f\"Explaining CatBoost: index={idx}, row={row}\")\n",
    "        explain_item(c_predict_fn, row)\n",
    "    for i in range(x):\n",
    "        print(f\"Explaining XGBoost: index={idx}, row={row}\")\n",
    "        explain_item(x_predict_fn, row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain Point 1 with all 3 Boosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_x_times(2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invert Gender for Point 1, Classify and Explain Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_x_times(2, 0, invert_gender=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain Point 2 with All Boosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_x_times(2, 1, invert_gender=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invert Gender for Point 2, Classify and Explain Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_x_times(2, 1, invert_gender=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "The above was an experiment on explaining a classification model with LIME. What about tabular data in regression models? In such case we try to predict a continous variable based on a set of features, as opposed to trying to classify someting to a specific category.\n",
    "\n",
    "This one uses the Boston housing prices dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\n",
    "df_test = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the Titanic dataset, I will just use a bunch of derived features copied from some existing Kaggle notebooks. Thanks again :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('Alley','Utilities','MasVnrType','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1',\n",
    "            'BsmtFinType2','FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond',\n",
    "           'PoolQC','Fence','MiscFeature'):\n",
    "    df_train[col]=df_train[col].fillna('None')\n",
    "    df_test[col]=df_test[col].fillna('None')\n",
    "\n",
    "for col in ('Electrical','MSZoning','Exterior1st','Exterior2nd','KitchenQual','SaleType','Functional'):\n",
    "    df_train[col]=df_train[col].fillna(df_train[col].mode()[0])\n",
    "    df_test[col]=df_test[col].fillna(df_train[col].mode()[0])\n",
    "\n",
    "for col in ('MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath',\n",
    "            'GarageYrBlt','GarageCars','GarageArea'):\n",
    "    df_train[col]=df_train[col].fillna(0)\n",
    "    df_test[col]=df_test[col].fillna(0)\n",
    "\n",
    "df_train['LotFrontage']=df_train['LotFrontage'].fillna(df_train['LotFrontage'].mean())\n",
    "df_test['LotFrontage']=df_test['LotFrontage'].fillna(df_train['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing outliers recomended by author\n",
    "df_train = df_train[df_train['GrLivArea']<4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_traindf = df_train.shape[0]\n",
    "houses = pd.concat([df_train, df_test], sort=False)\n",
    "houses = houses.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# turning some ordered categorical variables into ordered numerical\n",
    "# maybe this information about order can help on performance\n",
    "for col in [\"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"HeatingQC\", \"KitchenQual\",\n",
    "            \"FireplaceQu\",\"GarageQual\",\"GarageCond\",\"PoolQC\"]:\n",
    "    houses[col]= houses[col].map({\"Gd\": 4 , \"TA\": 3, \"Ex\": 5, \"Fa\":2, \"Po\":1})\n",
    "houses = houses.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, need the list of categorical feature names and indices as input for LIME explainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "\n",
    "cdf = df_train.select_dtypes(include=np.number)\n",
    "cat_names = [key for key in df_train.columns if key not in cdf.columns]\n",
    "cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_traindf = df_train.shape[0]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for col in cat_names:\n",
    "    le = LabelEncoder()\n",
    "    label_encoders[col] = le\n",
    "    houses[col] = le.fit_transform(houses[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am using XGBoostRegressor, I need the one-hot encoded categorical variables again, just like with the Titanic classifier above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = houses[:len_traindf]\n",
    "df_train = df_train.drop('SalePrice', axis=1)\n",
    "df_test = houses[len_traindf:]\n",
    "df_test = df_test.drop('SalePrice', axis=1)\n",
    "\n",
    "# turning categoric into numeric\n",
    "houses_oh = pd.get_dummies(houses)\n",
    "\n",
    "# separating\n",
    "df_train_oh = houses_oh[:len_traindf]\n",
    "df_test_oh = houses_oh[len_traindf:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x/y split\n",
    "X_train_oh = df_train_oh.drop('SalePrice', axis=1)\n",
    "y_train = df_train_oh['SalePrice']\n",
    "X_test_oh = df_test_oh.drop('SalePrice', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit of an overkill to optimize the hyperparameters with multiple runs over hyperopt, but the notebook I used as a source does it, so here we go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe, fmin\n",
    "\n",
    "space = {'n_estimators':hp.quniform('n_estimators', 1000, 4000, 100),\n",
    "         'gamma':hp.uniform('gamma', 0.01, 0.05),\n",
    "         'learning_rate':hp.uniform('learning_rate', 0.00001, 0.03),\n",
    "         'max_depth':hp.quniform('max_depth', 3,7,1),\n",
    "         'subsample':hp.uniform('subsample', 0.60, 0.95),\n",
    "         'colsample_bytree':hp.uniform('colsample_bytree', 0.60, 0.95),\n",
    "         'colsample_bylevel':hp.uniform('colsample_bylevel', 0.60, 0.95),\n",
    "         'reg_lambda': hp.uniform('reg_lambda', 1, 20)\n",
    "        }\n",
    "\n",
    "def objective(params):\n",
    "    params = {'n_estimators': int(params['n_estimators']),\n",
    "             'gamma': params['gamma'],\n",
    "             'learning_rate': params['learning_rate'],\n",
    "             'max_depth': int(params['max_depth']),\n",
    "             'subsample': params['subsample'],\n",
    "             'colsample_bytree': params['colsample_bytree'],\n",
    "             'colsample_bylevel': params['colsample_bylevel'],\n",
    "             'reg_lambda': params['reg_lambda']}\n",
    "    \n",
    "    xb_a = xgb.XGBRegressor(**params)\n",
    "    score = cross_val_score(xb_a, X_train_oh, y_train, scoring='neg_mean_squared_error', cv=5, n_jobs=-1).mean()\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fmin(fn= objective, space= space, max_evals=4, rstate=np.random.RandomState(1), algo=tpe.suggest)\n",
    "#max_evals=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be the actual regressor used and explained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf = xgb.XGBRegressor(random_state=0,\n",
    "                        n_estimators=int(best['n_estimators']), \n",
    "                        colsample_bytree= best['colsample_bytree'],\n",
    "                        gamma= best['gamma'],\n",
    "                        learning_rate= best['learning_rate'],\n",
    "                        max_depth= int(best['max_depth']),\n",
    "                        subsample= best['subsample'],\n",
    "                        colsample_bylevel= best['colsample_bylevel'],\n",
    "                        reg_lambda= best['reg_lambda']\n",
    "                       )\n",
    "\n",
    "X_clf.fit(X_train_oh, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And build a list of categorical column indices for LIME:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = list(df_train.columns)\n",
    "cat_indices = []\n",
    "for cat_name in cat_names:\n",
    "    cat_indices.append(all_cols.index(cat_name))\n",
    "print(cat_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of all feature names for LIME:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(df_train.columns)\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping of categorical feature names to their values and their names. Similar to the Titanic dataset above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = {}\n",
    "for label_idx in cat_indices:\n",
    "    label = feature_names[label_idx]\n",
    "    print(label)\n",
    "    le = label_encoders[label]\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    le_value_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "    print(le_value_mapping)\n",
    "    cat_names[label_idx] = le_value_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_oh = list(df_train_oh.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(df_train.values, \n",
    "                                                   feature_names=feature_names, \n",
    "                                                   class_names=['price'], \n",
    "                                                   categorical_features=cat_indices,\n",
    "                                                   categorical_names=cat_names,\n",
    "                                                   verbose=True, \n",
    "                                                   discretize_continuous=False,\n",
    "                                                   mode='regression')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_xreg(row):\n",
    "    df = pd.DataFrame(data=row, columns=df_train.columns)\n",
    "    row = pd.get_dummies(df)\n",
    "    return X_clf.predict(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_item(item):\n",
    "    exp = explainer.explain_instance(item, explain_xreg, num_features=10, top_labels=1)\n",
    "    exp.show_in_notebook(show_table=True, show_all=False)\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.iloc[0].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_xreg([df_test.iloc[0].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explain_item(df_test.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = exp.as_list()\n",
    "top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the explainer was created above using the top 10 features, the list also shows these 10 features. A brief look at each in this instance vs the overall dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat, weight in top_features:\n",
    "    print(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "top_names = [tup[0].split(\"=\")[0] for tup in top_features]\n",
    "df_test[top_names].hist(figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[top_names].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.iloc[0][\"KitchenQual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df_test.iloc[0]\n",
    "row[\"KitchenQual\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row[\"KitchenQual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explain_item(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining Keras NN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I tried to explain booster based classifiers and regressors using the scikit interfaces. Neural nets are another type of network often used, so how to fit LIME on a neural net? Here is an example of a classifier based on Keras fully connected neural network.\n",
    "\n",
    "This one uses the UCI heart disease dataset. As usual, the base preprocessing and model are based on some existing notebooks. Thanks for your efforts, whoever it was.. My point is simply to use it to try out LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv\n",
    "cleveland = pd.read_csv('../input/heart-disease-uci/heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing data (indicated with a \"?\")\n",
    "data = cleveland[~cleveland.isin(['?'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nans\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(pd.to_numeric)\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data.drop(['target'], 1))\n",
    "y = np.array(data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y, random_state=42, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data to categorical labels\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train, num_classes=None)\n",
    "Y_test = to_categorical(y_test, num_classes=None)\n",
    "print (Y_train.shape)\n",
    "print (Y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "# define a function to build the keras model\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=13, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(8, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to the training data\n",
    "#verbose=1 for full output, verbose=2 for list of epochs. 0 for quiet\n",
    "history=model.fit(X_train, Y_train, validation_data=(X_test, Y_test),epochs=50, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see training results, exact accuracy and loss\n",
    "#history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the accuracy and loss over epochs takes much less space.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Model accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Losss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into binary classification problem - heart disease or no heart disease\n",
    "Y_train_binary = y_train.copy()\n",
    "Y_test_binary = y_test.copy()\n",
    "\n",
    "Y_train_binary[Y_train_binary > 0] = 1\n",
    "Y_test_binary[Y_test_binary > 0] = 1\n",
    "\n",
    "print(Y_train_binary[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel I am basing on finished with a binary model simpler analysis of output. So here we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a new keras model for binary classification\n",
    "def create_binary_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=13, kernel_initializer='normal',  kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(8, kernel_initializer='normal',  kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "binary_model = create_binary_model()\n",
    "\n",
    "print(binary_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "\n",
    "binary_model = KerasClassifier(build_fn=create_binary_model, epochs=50, batch_size=10, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the binary model on the training data\n",
    "history=binary_model.fit(X_train, Y_train_binary, validation_data=(X_test, Y_test_binary), epochs=50, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Model accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Losss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_pimp_2(pimps, features):\n",
    "    importances = pimps.importances_mean\n",
    "\n",
    "    feat_importances = pd.DataFrame()\n",
    "    feat_importances[\"weight\"] = importances\n",
    "    feat_importances.index = features\n",
    "    feat_importances.sort_values(by=\"weight\", ascending=False).to_csv(f\"top_features.csv\")\n",
    "    feat_importances.nlargest(30, [\"weight\"]).sort_values(by=\"weight\").plot(kind='barh', title=f\"top features\", color='#86bf91', figsize=(10, 8))\n",
    "    # kaggle shows output image files (like this png) under \"output visualizations\", others (such as pdf) under \"output\"\n",
    "    plt.savefig(f'feature-weights.png')\n",
    "    plt.savefig(f'feature-weights.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = data.drop(['target'], 1)\n",
    "k_pimps = permutation_importance(binary_model, X_train, y_train, n_repeats=10, random_state=0)\n",
    "plot_pimp_2(k_pimps, df_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate classification report using predictions for categorical model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "categorical_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "print('Results for Categorical Model')\n",
    "print(accuracy_score(y_test, categorical_pred))\n",
    "print(classification_report(y_test, categorical_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cleveland.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to recall the variables before we try to explain some datapoints from this predictor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- age\n",
    "- sex\n",
    "- chest pain type (4 values)\n",
    "- resting blood pressure\n",
    "- serum cholestoral in mg/dl\n",
    "- fasting blood sugar > 120 mg/dl\n",
    "- resting electrocardiographic results (values 0,1,2)\n",
    "- maximum heart rate achieved\n",
    "- exercise induced angina\n",
    "- oldpeak = ST depression induced by exercise relative to rest\n",
    "- the slope of the peak exercise ST segment\n",
    "- number of major vessels (0-3) colored by flourosopy\n",
    "- thal: 3 = normal; 6 = fixed defect; 7 = reversable defect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"thalach\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical columns and number of values / categories for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"ca\", \"thal\"]\n",
    "for col in cat_cols:\n",
    "    print(f\"{col}: {data[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical column indices in the list of columns, needed for LIME to print the names on explanations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(feature_names)\n",
    "cat_indices = [feature_names.index(col) for col in cat_cols]\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explainer = lime.lime_tabular.LimeTabularExplainer(df_train, feature_names=iris.feature_names, class_names=iris.target_names, discretize_continuous=True)\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train, discretize_continuous=True,\n",
    "                                                   class_names=['no risk', 'risk of heart'], \n",
    "                                                   mode=\"classification\",\n",
    "                                                   feature_names = feature_names,\n",
    "                                                   categorical_features=cat_indices,\n",
    "                                                   categorical_names=[], \n",
    "                                                   kernel_width=10, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_item(item):\n",
    "\n",
    "    #    exp = explainer.explain_instance(item, l_predict_fn, num_features=10, top_labels=1)\n",
    "    exp = explainer.explain_instance(item, model.predict_proba, num_features=10, top_labels=1)\n",
    "#    exp = explainer.explain_instance(item, l_clf.predict_proba, num_features=10, top_labels=1)\n",
    "    exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_item_flipped(row, flip=False):\n",
    "    if flip:\n",
    "        if row[2] > 0:\n",
    "            row[2] = 0\n",
    "        else:\n",
    "            row[2] = 1\n",
    "    print(f\"columns={X_val.columns}\")\n",
    "    #    exp = explainer.explain_instance(item, l_predict_fn, num_features=10, top_labels=1)\n",
    "    exp = explainer.explain_instance(row, model.predict_proba, num_features=10, top_labels=1)\n",
    "#    exp = explainer.explain_instance(item, l_clf.predict_proba, num_features=10, top_labels=1)\n",
    "    exp.show_in_notebook(show_table=True, show_all=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_item(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_item_flipped(X_test[0], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_item_flipped(X_test[1], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_item_flipped(X_test[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_item_flipped(X_test[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
